{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2013 Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from   sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from   sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from   sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from   sklearn.model_selection import cross_val_score\n",
    "from   sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_data(date=''):\n",
    "    '''\n",
    "    The Billboard Hot 100 chart represents the Hot 100 songs for that week.\n",
    "    \n",
    "    date: a string, in the form \"YYYY-MM-DD\". For example, \"2022-05-16\" represents May 16, 2022. If no date specified, function\n",
    "          will select the present chart\n",
    "    returns: a pandas dataframe containing metadata for Billboard Hot 100 songs of the week of the specified date.\n",
    "    columns: rank: rank of the week (1-100)\n",
    "             date: a pandas datetime object. date of the chart as stated on the Billboard website, \n",
    "             which uses the Saturday to identify the week (so it is the same week as the user input, but the Saturday\n",
    "             of that week),\n",
    "             title: title of the song,\n",
    "             artist1: main artist,\n",
    "             artist2: a list of the rest of the artists. np.nan if there are none.\n",
    "             peak_pos: peak position of the song,\n",
    "             wks_chart: # of weeks the song has been on the chart\n",
    "             b_url: url to the billboard chart\n",
    "    '''\n",
    "    lsongs=[]\n",
    "    lartists=[]\n",
    "    artist1=[]\n",
    "    artist2=[]\n",
    "    lpeak_pos=[]\n",
    "    lwks_chart=[]\n",
    "    \n",
    "    URL='https://www.billboard.com/charts/hot-100/'+date\n",
    "\n",
    "    page=requests.get(URL)\n",
    "    soup=BeautifulSoup(page.content, 'lxml')\n",
    "  \n",
    "    ### get the first song, bc it's in a different div container\n",
    "    song1 = soup.find(\"h3\",id='title-of-a-story', class_=\"c-title a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet\")\n",
    "    lsongs.append(song1.text.strip())\n",
    "    \n",
    "    ### get the first artist, bc it's in a different div container\n",
    "    artistf=soup.find(\"span\", class_=\"c-label a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\")\n",
    "    lartists.append(artistf.text.strip())\n",
    "    \n",
    "    ### get the first peak position, bc it's in a different div container\n",
    "    nums=soup.find_all('span', class_=\"c-label a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet\")\n",
    "    nums1=[]\n",
    "    for x in nums:\n",
    "        nums1.append(x.text.strip())\n",
    "        \n",
    "    lpeak_pos.append(nums1[1])\n",
    "    ### get the first weeks on chart, bc it's in a different div container\n",
    "    lwks_chart.append(nums1[2])\n",
    "    \n",
    "    ### get last 99 songs\n",
    "    songs = soup.find_all(\"h3\", class_=\"c-title a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\", id=\"title-of-a-story\")\n",
    "    for song in songs:\n",
    "        lsongs.append(song.text.strip())\n",
    "    \n",
    "    ### get last 99 artists\n",
    "    artists = soup.find_all(\"span\", class_=\"c-label a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\")\n",
    "    for artist in artists:\n",
    "        lartists.append(artist.text.strip())\n",
    "        \n",
    "    ### get last 99 peak position\n",
    "    all_num=[]\n",
    "    peak_pos = soup.find_all(\"span\", class_=\"c-label a-font-primary-m lrv-u-padding-tb-050@mobile-max\")\n",
    "    for num in peak_pos:\n",
    "        all_num.append(num.text.strip())\n",
    "    \n",
    "    x=1\n",
    "    for peak in all_num:\n",
    "        if x <= len(all_num)-5:\n",
    "            lpeak_pos.append(all_num[x])\n",
    "            x=x+6\n",
    "\n",
    "    ### get last 99 weeks on chart\n",
    "    y=2\n",
    "    for wk in all_num:\n",
    "        if y <= len(all_num)-4:\n",
    "            lwks_chart.append(all_num[y])\n",
    "            y=y+6            \n",
    "    \n",
    "    ### get date as listed on the chart, aka the Saturday of the week of the user input\n",
    "    date=soup.find('h2', id=\"section-heading\")\n",
    "    cdate=pd.to_datetime(date.text.strip().replace(\"Week of \",''))\n",
    "    \n",
    "    \n",
    "    ### separate artists into artist1 and artist2\n",
    "    for a in lartists:\n",
    "        if (\"X &\" not in a) and (\"X Featuring\" not in a) and (\"X /\" not in a):\n",
    "            a=a.replace(\" X \",\",\")\n",
    "        a=a.replace(\"Featuring\",\",\")\n",
    "        a=a.replace(\"&\",\",\")   \n",
    "        a=a.replace(\" / \",\",\")\n",
    "        List=a.split(\",\")\n",
    "        artists = [i.strip() for i in List]\n",
    "        artist1.append(artists[0])\n",
    "        if len(artists)==1:\n",
    "            artist2.append(np.nan)\n",
    "        else:\n",
    "            artist2.append(artists[1:])\n",
    "    \n",
    "    metadata=pd.DataFrame()\n",
    "    metadata['rank']=(range(1,101)) ### get rank position\n",
    "    metadata['date']=cdate\n",
    "    metadata['title']=lsongs\n",
    "    metadata['artist1']=artist1\n",
    "    metadata['artist2']=artist2\n",
    "    metadata['peak_pos']=lpeak_pos\n",
    "    metadata['wks_chart']=lwks_chart\n",
    "    metadata['b_url']=URL\n",
    "    \n",
    "    metadata=append_lyrics(metadata)\n",
    "    metadata.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_lyrics(metadata):\n",
    "    '''\n",
    "    a helper function for song_data(). gets the song lyrics for a given song. appends the\n",
    "    song lyrics for a song from Genius.com to a \"lyrics\" column.\n",
    "    \n",
    "    If the function cannot find the song on the Genius lyrics website, it will drop the entire observation from the dataset.\n",
    "    \n",
    "    metadata: a pandas dataframe, created from song_data(). at the least contains\n",
    "              the title column and the artist1 column.\n",
    "    returns: a pandas dataframe of the original dataframe with a lyrics column and URL to the\n",
    "             Genius website the lyrics were taken from.\n",
    "    '''\n",
    "    all_lyrics=[]\n",
    "    all_URL=[]\n",
    "    title=metadata.title.values\n",
    "    artist1=metadata.artist1.values\n",
    "    for x in range(len(title)):\n",
    "        t=title[x]\n",
    "        a=artist1[x]\n",
    "  \n",
    "        t=re.sub(r'[^\\w\\s]', '', t)\n",
    "        a=re.sub(r'[!$/]', '-', a)\n",
    "        a=re.sub(r'[\"\\\\#%&;\\()*\\[\\]+,.:;<=>?@^_`{|}~]', '', a) #[\\\\]\n",
    "        URL= \"https://www.genius.com/\"+a.replace(' ','-')+'-'+t.replace(' ','-')+'-lyrics'\n",
    "        URL=URL.replace('--','-')\n",
    "        \n",
    "        page=requests.get(URL)\n",
    "        soup=BeautifulSoup(page.content, 'lxml')\n",
    "        if 'Oops! Page not found' not in soup.text.strip():\n",
    "            lyrics=soup.find_all('div', class_='Lyrics__Container-sc-1ynbvzw-6 jYfhrf')\n",
    "            Lyrics = [re.sub(r\"\\[.*?\\]\",'',i.text.strip()) for i in lyrics]\n",
    "            LYRICS=\" \".join(Lyrics)\n",
    "            all_lyrics.append(LYRICS)\n",
    "            all_URL.append(URL)\n",
    "        \n",
    "        else: \n",
    "            #print(URL)\n",
    "            metadata.drop([x], inplace=True)\n",
    "    \n",
    "    metadata['lyrics']=all_lyrics\n",
    "    metadata['g_url']=all_URL\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "DatetimeIndex(['2013-01-05', '2013-01-12', '2013-01-19', '2013-01-26',\n",
      "               '2013-02-02', '2013-02-09', '2013-02-16', '2013-02-23',\n",
      "               '2013-03-02', '2013-03-09', '2013-03-16', '2013-03-23',\n",
      "               '2013-03-30', '2013-04-06', '2013-04-13', '2013-04-20',\n",
      "               '2013-04-27', '2013-05-04', '2013-05-11', '2013-05-18',\n",
      "               '2013-05-25', '2013-06-01', '2013-06-08', '2013-06-15',\n",
      "               '2013-06-22', '2013-06-29', '2013-07-06', '2013-07-13',\n",
      "               '2013-07-20', '2013-07-27', '2013-08-03', '2013-08-10',\n",
      "               '2013-08-17', '2013-08-24', '2013-08-31', '2013-09-07',\n",
      "               '2013-09-14', '2013-09-21', '2013-09-28', '2013-10-05',\n",
      "               '2013-10-12', '2013-10-19', '2013-10-26', '2013-11-02',\n",
      "               '2013-11-09', '2013-11-16', '2013-11-23', '2013-11-30',\n",
      "               '2013-12-07', '2013-12-14', '2013-12-21', '2013-12-28'],\n",
      "              dtype='datetime64[ns]', freq='W-SAT')\n"
     ]
    }
   ],
   "source": [
    "dates=pd.date_range(start='2013-01-01',end='2013-12-31',freq='W-SAT')\n",
    "print(len(dates))\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dates=[date.strftime('%Y-%m-%d') for date in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-01-05\n",
      "2013-01-12\n",
      "2013-01-19\n",
      "2013-01-26\n",
      "2013-02-02\n",
      "2013-02-09\n",
      "2013-02-16\n",
      "2013-02-23\n",
      "2013-03-02\n",
      "2013-03-09\n",
      "2013-03-16\n",
      "2013-03-23\n",
      "2013-03-30\n",
      "2013-04-06\n",
      "2013-04-13\n",
      "2013-04-20\n",
      "2013-04-27\n",
      "2013-05-04\n",
      "2013-05-11\n",
      "2013-05-18\n",
      "2013-05-25\n",
      "2013-06-01\n",
      "2013-06-08\n",
      "2013-06-15\n",
      "2013-06-22\n",
      "2013-06-29\n",
      "2013-07-06\n",
      "2013-07-13\n",
      "2013-07-20\n",
      "2013-07-27\n",
      "2013-08-03\n",
      "2013-08-10\n",
      "2013-08-17\n",
      "2013-08-24\n",
      "2013-08-31\n",
      "2013-09-07\n",
      "2013-09-14\n",
      "2013-09-21\n",
      "2013-09-28\n",
      "2013-10-05\n",
      "2013-10-12\n",
      "2013-10-19\n",
      "2013-10-26\n",
      "2013-11-02\n",
      "2013-11-09\n",
      "2013-11-16\n",
      "2013-11-23\n",
      "2013-11-30\n",
      "2013-12-07\n",
      "2013-12-14\n",
      "2013-12-21\n",
      "2013-12-28\n"
     ]
    }
   ],
   "source": [
    "songs=[]\n",
    "for date in Dates:\n",
    "    songs.append(song_data(date))\n",
    "    print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat(songs)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.to_csv('songs2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5121"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
