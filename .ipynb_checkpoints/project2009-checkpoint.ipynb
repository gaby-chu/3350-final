{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2009 Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from   sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from   sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from   sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from   sklearn.model_selection import cross_val_score\n",
    "from   sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_data(date=''):\n",
    "    '''\n",
    "    The Billboard Hot 100 chart represents the Hot 100 songs for that week.\n",
    "    \n",
    "    date: a string, in the form \"YYYY-MM-DD\". For example, \"2022-05-16\" represents May 16, 2022. If no date specified, function\n",
    "          will select the present chart\n",
    "    returns: a pandas dataframe containing metadata for Billboard Hot 100 songs of the week of the specified date.\n",
    "    columns: rank: rank of the week (1-100)\n",
    "             date: a pandas datetime object. date of the chart as stated on the Billboard website, \n",
    "             which uses the Saturday to identify the week (so it is the same week as the user input, but the Saturday\n",
    "             of that week),\n",
    "             title: title of the song,\n",
    "             artist1: main artist,\n",
    "             artist2: a list of the rest of the artists. np.nan if there are none.\n",
    "             peak_pos: peak position of the song,\n",
    "             wks_chart: # of weeks the song has been on the chart\n",
    "             b_url: url to the billboard chart\n",
    "    '''\n",
    "    lsongs=[]\n",
    "    lartists=[]\n",
    "    artist1=[]\n",
    "    artist2=[]\n",
    "    lpeak_pos=[]\n",
    "    lwks_chart=[]\n",
    "    \n",
    "    URL='https://www.billboard.com/charts/hot-100/'+date\n",
    "\n",
    "    page=requests.get(URL)\n",
    "    soup=BeautifulSoup(page.content, 'lxml')\n",
    "  \n",
    "    ### get the first song, bc it's in a different div container\n",
    "    song1 = soup.find(\"h3\",id='title-of-a-story', class_=\"c-title a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet\")\n",
    "    lsongs.append(song1.text.strip())\n",
    "    \n",
    "    ### get the first artist, bc it's in a different div container\n",
    "    artistf=soup.find(\"span\", class_=\"c-label a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\")\n",
    "    lartists.append(artistf.text.strip())\n",
    "    \n",
    "    ### get the first peak position, bc it's in a different div container\n",
    "    nums=soup.find_all('span', class_=\"c-label a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet\")\n",
    "    nums1=[]\n",
    "    for x in nums:\n",
    "        nums1.append(x.text.strip())\n",
    "        \n",
    "    lpeak_pos.append(nums1[1])\n",
    "    ### get the first weeks on chart, bc it's in a different div container\n",
    "    lwks_chart.append(nums1[2])\n",
    "    \n",
    "    ### get last 99 songs\n",
    "    songs = soup.find_all(\"h3\", class_=\"c-title a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\", id=\"title-of-a-story\")\n",
    "    for song in songs:\n",
    "        lsongs.append(song.text.strip())\n",
    "    \n",
    "    ### get last 99 artists\n",
    "    artists = soup.find_all(\"span\", class_=\"c-label a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\")\n",
    "    for artist in artists:\n",
    "        lartists.append(artist.text.strip())\n",
    "        \n",
    "    ### get last 99 peak position\n",
    "    all_num=[]\n",
    "    peak_pos = soup.find_all(\"span\", class_=\"c-label a-font-primary-m lrv-u-padding-tb-050@mobile-max\")\n",
    "    for num in peak_pos:\n",
    "        all_num.append(num.text.strip())\n",
    "    \n",
    "    x=1\n",
    "    for peak in all_num:\n",
    "        if x <= len(all_num)-5:\n",
    "            lpeak_pos.append(all_num[x])\n",
    "            x=x+6\n",
    "\n",
    "    ### get last 99 weeks on chart\n",
    "    y=2\n",
    "    for wk in all_num:\n",
    "        if y <= len(all_num)-4:\n",
    "            lwks_chart.append(all_num[y])\n",
    "            y=y+6            \n",
    "    \n",
    "    ### get date as listed on the chart, aka the Saturday of the week of the user input\n",
    "    date=soup.find('h2', id=\"section-heading\")\n",
    "    cdate=pd.to_datetime(date.text.strip().replace(\"Week of \",''))\n",
    "    \n",
    "    \n",
    "    ### separate artists into artist1 and artist2\n",
    "    for a in lartists:\n",
    "        if (\"X &\" not in a) and (\"X Featuring\" not in a) and (\"X /\" not in a):\n",
    "            a=a.replace(\" X \",\",\")\n",
    "        a=a.replace(\"Featuring\",\",\")\n",
    "        a=a.replace(\"&\",\",\")   \n",
    "        a=a.replace(\" / \",\",\")\n",
    "        List=a.split(\",\")\n",
    "        artists = [i.strip() for i in List]\n",
    "        artist1.append(artists[0])\n",
    "        if len(artists)==1:\n",
    "            artist2.append(np.nan)\n",
    "        else:\n",
    "            artist2.append(artists[1:])\n",
    "    \n",
    "    metadata=pd.DataFrame()\n",
    "    metadata['rank']=(range(1,101)) ### get rank position\n",
    "    metadata['date']=cdate\n",
    "    metadata['title']=lsongs\n",
    "    metadata['artist1']=artist1\n",
    "    metadata['artist2']=artist2\n",
    "    metadata['peak_pos']=lpeak_pos\n",
    "    metadata['wks_chart']=lwks_chart\n",
    "    metadata['b_url']=URL\n",
    "    \n",
    "    metadata=append_lyrics(metadata)\n",
    "    metadata.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_lyrics(metadata):\n",
    "    '''\n",
    "    a helper function for song_data(). gets the song lyrics for a given song. appends the\n",
    "    song lyrics for a song from Genius.com to a \"lyrics\" column.\n",
    "    \n",
    "    If the function cannot find the song on the Genius lyrics website, it will drop the entire observation from the dataset.\n",
    "    \n",
    "    metadata: a pandas dataframe, created from song_data(). at the least contains\n",
    "              the title column and the artist1 column.\n",
    "    returns: a pandas dataframe of the original dataframe with a lyrics column and URL to the\n",
    "             Genius website the lyrics were taken from.\n",
    "    '''\n",
    "    all_lyrics=[]\n",
    "    all_URL=[]\n",
    "    title=metadata.title.values\n",
    "    artist1=metadata.artist1.values\n",
    "    for x in range(len(title)):\n",
    "        t=title[x]\n",
    "        a=artist1[x]\n",
    "  \n",
    "        t=re.sub(r'[^\\w\\s]', '', t)\n",
    "        a=re.sub(r'[!$/]', '-', a)\n",
    "        a=re.sub(r'[\"\\\\#%&;\\()*\\[\\]+,.:;<=>?@^_`{|}~]', '', a) #[\\\\]\n",
    "        URL= \"https://www.genius.com/\"+a.replace(' ','-')+'-'+t.replace(' ','-')+'-lyrics'\n",
    "        URL=URL.replace('--','-')\n",
    "        \n",
    "        page=requests.get(URL)\n",
    "        soup=BeautifulSoup(page.content, 'lxml')\n",
    "        if 'Oops! Page not found' not in soup.text.strip():\n",
    "            lyrics=soup.find_all('div', class_='Lyrics__Container-sc-1ynbvzw-6 jYfhrf')\n",
    "            Lyrics = [re.sub(r\"\\[.*?\\]\",'',i.text.strip()) for i in lyrics]\n",
    "            LYRICS=\" \".join(Lyrics)\n",
    "            all_lyrics.append(LYRICS)\n",
    "            all_URL.append(URL)\n",
    "        \n",
    "        else: \n",
    "            #print(URL)\n",
    "            metadata.drop([x], inplace=True)\n",
    "    \n",
    "    metadata['lyrics']=all_lyrics\n",
    "    metadata['g_url']=all_URL\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "DatetimeIndex(['2009-01-03', '2009-01-10', '2009-01-17', '2009-01-24',\n",
      "               '2009-01-31', '2009-02-07', '2009-02-14', '2009-02-21',\n",
      "               '2009-02-28', '2009-03-07', '2009-03-14', '2009-03-21',\n",
      "               '2009-03-28', '2009-04-04', '2009-04-11', '2009-04-18',\n",
      "               '2009-04-25', '2009-05-02', '2009-05-09', '2009-05-16',\n",
      "               '2009-05-23', '2009-05-30', '2009-06-06', '2009-06-13',\n",
      "               '2009-06-20', '2009-06-27', '2009-07-04', '2009-07-11',\n",
      "               '2009-07-18', '2009-07-25', '2009-08-01', '2009-08-08',\n",
      "               '2009-08-15', '2009-08-22', '2009-08-29', '2009-09-05',\n",
      "               '2009-09-12', '2009-09-19', '2009-09-26', '2009-10-03',\n",
      "               '2009-10-10', '2009-10-17', '2009-10-24', '2009-10-31',\n",
      "               '2009-11-07', '2009-11-14', '2009-11-21', '2009-11-28',\n",
      "               '2009-12-05', '2009-12-12', '2009-12-19', '2009-12-26'],\n",
      "              dtype='datetime64[ns]', freq='W-SAT')\n"
     ]
    }
   ],
   "source": [
    "dates=pd.date_range(start='2009-01-01',end='2009-12-31',freq='W-SAT')\n",
    "print(len(dates))\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dates=[date.strftime('%Y-%m-%d') for date in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_dates(datelist):\n",
    "    '''\n",
    "    a preprocessing function to check if a chart exists for a given date.\n",
    "    e.g. https://www.billboard.com/charts/hot-100/2011-08-06/ does not have a chart, but https://www.billboard.com/charts/hot-100/2011-08-13/ does.\n",
    "    removes broken links from a list of dates.\n",
    "    i.e. if a Billboard chart does not exist for a date specified in a list, remove the date from the list.\n",
    "    \n",
    "    datelist: a list of strings, each dates in YYYY-MM-DD format.\n",
    "    returns: a list of valid dates from the datelist.\n",
    "    '''\n",
    "    valid=[]\n",
    "    for date in datelist:\n",
    "        URL='https://www.billboard.com/charts/hot-100/'+date\n",
    "        page=requests.get(URL)\n",
    "        soup=BeautifulSoup(page.content, 'lxml')\n",
    "        song1 = soup.find(\"h3\",id='title-of-a-story', class_=\"c-title a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet\")\n",
    "        if song1 != None:\n",
    "            valid.append(date)\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATES=valid_dates(Dates)\n",
    "print(len(Dates))\n",
    "len(DATES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-01-03\n",
      "2009-01-10\n",
      "2009-01-17\n",
      "2009-01-24\n",
      "2009-01-31\n",
      "2009-02-07\n",
      "2009-02-14\n",
      "2009-02-21\n",
      "2009-02-28\n",
      "2009-03-07\n",
      "2009-03-14\n",
      "2009-03-21\n",
      "2009-03-28\n",
      "2009-04-04\n",
      "2009-04-11\n",
      "2009-04-18\n",
      "2009-04-25\n",
      "2009-05-02\n",
      "2009-05-09\n",
      "2009-05-16\n",
      "2009-05-23\n",
      "2009-05-30\n",
      "2009-06-06\n",
      "2009-06-13\n",
      "2009-06-20\n",
      "2009-06-27\n",
      "2009-07-04\n",
      "2009-07-11\n",
      "2009-07-18\n",
      "2009-07-25\n",
      "2009-08-01\n",
      "2009-08-08\n",
      "2009-08-15\n",
      "2009-08-22\n",
      "2009-08-29\n",
      "2009-09-05\n",
      "2009-09-12\n",
      "2009-09-19\n",
      "2009-09-26\n",
      "2009-10-03\n",
      "2009-10-10\n",
      "2009-10-17\n",
      "2009-10-24\n",
      "2009-10-31\n",
      "2009-11-07\n",
      "2009-11-14\n",
      "2009-11-21\n",
      "2009-11-28\n",
      "2009-12-05\n",
      "2009-12-12\n",
      "2009-12-19\n",
      "2009-12-26\n"
     ]
    }
   ],
   "source": [
    "songs=[]\n",
    "for date in DATES:\n",
    "    songs.append(song_data(date))\n",
    "    print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat(songs)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df.to_csv('songs2009.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>artist1</th>\n",
       "      <th>artist2</th>\n",
       "      <th>peak_pos</th>\n",
       "      <th>wks_chart</th>\n",
       "      <th>b_url</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>g_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>Single Ladies (Put A Ring On It)</td>\n",
       "      <td>Beyonce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2009-...</td>\n",
       "      <td>All the single ladies (All the single ladies)A...</td>\n",
       "      <td>https://www.genius.com/Beyonce-Single-Ladies-P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>Live Your Life</td>\n",
       "      <td>T.I.</td>\n",
       "      <td>[Rihanna]</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2009-...</td>\n",
       "      <td>Miya hee, miya ho, miya hu, miya ha-haMiya hee...</td>\n",
       "      <td>https://www.genius.com/TI-Live-Your-Life-lyrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>Just Dance</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>[Colby O'Donis]</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2009-...</td>\n",
       "      <td>Truth!RedOneKonvictGaga (Oh-oh, eh)I've had a ...</td>\n",
       "      <td>https://www.genius.com/Lady-Gaga-Just-Dance-ly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>Heartless</td>\n",
       "      <td>Kanye West</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2009-...</td>\n",
       "      <td>In the night, I hear 'em talkThe coldest story...</td>\n",
       "      <td>https://www.genius.com/Kanye-West-Heartless-ly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>Womanizer</td>\n",
       "      <td>Britney Spears</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2009-...</td>\n",
       "      <td>Superstar, where you from? How's it goin'?I kn...</td>\n",
       "      <td>https://www.genius.com/Britney-Spears-Womanize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>95</td>\n",
       "      <td>2009-12-26</td>\n",
       "      <td>(If You're Wondering If I Want You To) I Want ...</td>\n",
       "      <td>Weezer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2009-...</td>\n",
       "      <td>The moon was shining on the lake at nightThe S...</td>\n",
       "      <td>https://www.genius.com/Weezer-If-Youre-Wonderi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4816</th>\n",
       "      <td>97</td>\n",
       "      <td>2009-12-26</td>\n",
       "      <td>Video Phone</td>\n",
       "      <td>Beyonce</td>\n",
       "      <td>[Lady Gaga]</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2009-...</td>\n",
       "      <td>Shawty, whatcha name is?Them hustlas keep on t...</td>\n",
       "      <td>https://www.genius.com/Beyonce-Video-Phone-lyrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4817</th>\n",
       "      <td>98</td>\n",
       "      <td>2009-12-26</td>\n",
       "      <td>Drop It Low</td>\n",
       "      <td>Ester Dean</td>\n",
       "      <td>[Chris Brown]</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2009-...</td>\n",
       "      <td>Drop it, drop it low, girl, drop it, drop it l...</td>\n",
       "      <td>https://www.genius.com/Ester-Dean-Drop-It-Low-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4818</th>\n",
       "      <td>99</td>\n",
       "      <td>2009-12-26</td>\n",
       "      <td>Halfway Gone</td>\n",
       "      <td>Lifehouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2009-...</td>\n",
       "      <td>Halfway gone, I'm halfway goneYou were always ...</td>\n",
       "      <td>https://www.genius.com/Lifehouse-Halfway-Gone-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4819</th>\n",
       "      <td>100</td>\n",
       "      <td>2009-12-26</td>\n",
       "      <td>Twang</td>\n",
       "      <td>George Strait</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2009-...</td>\n",
       "      <td>When I get off of work on Friday after working...</td>\n",
       "      <td>https://www.genius.com/George-Strait-Twang-lyrics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4820 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rank       date                                              title  \\\n",
       "0        1 2009-01-03                   Single Ladies (Put A Ring On It)   \n",
       "1        2 2009-01-03                                     Live Your Life   \n",
       "2        3 2009-01-03                                         Just Dance   \n",
       "3        4 2009-01-03                                          Heartless   \n",
       "4        5 2009-01-03                                          Womanizer   \n",
       "...    ...        ...                                                ...   \n",
       "4815    95 2009-12-26  (If You're Wondering If I Want You To) I Want ...   \n",
       "4816    97 2009-12-26                                        Video Phone   \n",
       "4817    98 2009-12-26                                        Drop It Low   \n",
       "4818    99 2009-12-26                                       Halfway Gone   \n",
       "4819   100 2009-12-26                                              Twang   \n",
       "\n",
       "             artist1          artist2 peak_pos wks_chart  \\\n",
       "0            Beyonce              NaN        1        10   \n",
       "1               T.I.        [Rihanna]        1        13   \n",
       "2          Lady Gaga  [Colby O'Donis]        3        20   \n",
       "3         Kanye West              NaN        4         7   \n",
       "4     Britney Spears              NaN        1        12   \n",
       "...              ...              ...      ...       ...   \n",
       "4815          Weezer              NaN       81         7   \n",
       "4816         Beyonce      [Lady Gaga]       65         3   \n",
       "4817      Ester Dean    [Chris Brown]       38        14   \n",
       "4818       Lifehouse              NaN       99         1   \n",
       "4819   George Strait              NaN      100         1   \n",
       "\n",
       "                                                  b_url  \\\n",
       "0     https://www.billboard.com/charts/hot-100/2009-...   \n",
       "1     https://www.billboard.com/charts/hot-100/2009-...   \n",
       "2     https://www.billboard.com/charts/hot-100/2009-...   \n",
       "3     https://www.billboard.com/charts/hot-100/2009-...   \n",
       "4     https://www.billboard.com/charts/hot-100/2009-...   \n",
       "...                                                 ...   \n",
       "4815  https://www.billboard.com/charts/hot-100/2009-...   \n",
       "4816  https://www.billboard.com/charts/hot-100/2009-...   \n",
       "4817  https://www.billboard.com/charts/hot-100/2009-...   \n",
       "4818  https://www.billboard.com/charts/hot-100/2009-...   \n",
       "4819  https://www.billboard.com/charts/hot-100/2009-...   \n",
       "\n",
       "                                                 lyrics  \\\n",
       "0     All the single ladies (All the single ladies)A...   \n",
       "1     Miya hee, miya ho, miya hu, miya ha-haMiya hee...   \n",
       "2     Truth!RedOneKonvictGaga (Oh-oh, eh)I've had a ...   \n",
       "3     In the night, I hear 'em talkThe coldest story...   \n",
       "4     Superstar, where you from? How's it goin'?I kn...   \n",
       "...                                                 ...   \n",
       "4815  The moon was shining on the lake at nightThe S...   \n",
       "4816  Shawty, whatcha name is?Them hustlas keep on t...   \n",
       "4817  Drop it, drop it low, girl, drop it, drop it l...   \n",
       "4818  Halfway gone, I'm halfway goneYou were always ...   \n",
       "4819  When I get off of work on Friday after working...   \n",
       "\n",
       "                                                  g_url  \n",
       "0     https://www.genius.com/Beyonce-Single-Ladies-P...  \n",
       "1       https://www.genius.com/TI-Live-Your-Life-lyrics  \n",
       "2     https://www.genius.com/Lady-Gaga-Just-Dance-ly...  \n",
       "3     https://www.genius.com/Kanye-West-Heartless-ly...  \n",
       "4     https://www.genius.com/Britney-Spears-Womanize...  \n",
       "...                                                 ...  \n",
       "4815  https://www.genius.com/Weezer-If-Youre-Wonderi...  \n",
       "4816  https://www.genius.com/Beyonce-Video-Phone-lyrics  \n",
       "4817  https://www.genius.com/Ester-Dean-Drop-It-Low-...  \n",
       "4818  https://www.genius.com/Lifehouse-Halfway-Gone-...  \n",
       "4819  https://www.genius.com/George-Strait-Twang-lyrics  \n",
       "\n",
       "[4820 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
