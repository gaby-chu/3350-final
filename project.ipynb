{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project guidelines\n",
    "\n",
    "**Note:** Use these guidelines if and only if you are pursuing a **final project of your own design**. For those taking the final exam instead of the project, see the (separate) [final exam notebook](https://github.com/wilkens-teaching/info3350-s22/blob/main/final_exam/exam.ipynb).\n",
    "\n",
    "## Guidelines\n",
    "\n",
    "These guidelines are intended for **undergraduates enrolled in INFO 3350**. If you are a graduate student enrolled in INFO 6350, you're welcome to consult the information below, but you have wider latitude to design and develop your project in line with your research goals.\n",
    "\n",
    "### The task\n",
    "\n",
    "Your task is to: identify an interesting problem connected to the humanities or humanistic social sciences that's addressable with the help of computational methods, formulate a hypothesis about it, devise an experiment or experiments to test your hypothesis, present the results of your investigations, and discuss your findings.\n",
    "\n",
    "These tasks essentially replicate the process of writing an academic paper. You can think of your project as a paper in miniature.\n",
    "\n",
    "You are free to present each of these tasks as you see fit. You should use narrative text (that is, your own writing in a markdown cell), citations of others' work, numerical results, tables of data, and static and/or interactive visualizations as appropriate. Total length is flexible and depends on the number of people involved in the work, as well as the specific balance you strike between the ambition of your question and the sophistication of your methods. But be aware that numbers never, ever speak for themselves. Quantitative results presented without substantial discussion will not earn high marks. \n",
    "\n",
    "Your project should reflect, at minimum, ten or more hours of work by each participant, though you will be graded on the quality of your work, not the amount of time it took you to produce it.\n",
    "\n",
    "#### Pick an important and interesting problem!\n",
    "\n",
    "No amount of technical sophistication will overcome a fundamentally uninteresting problem at the core of your work. You have seen many pieces of successful computational humanities research over the course of the semester. You might use these as a guide to the kinds of problems that interest scholars in a range of humanities disciplines. You may also want to spend some time in the library, reading recent books and articles in the professional literature. **Problem selection and motivation are integral parts of the project.** Do not neglect them.\n",
    "\n",
    "### Format\n",
    "\n",
    "You should submit your project as a Jupyter notebook, along with all data necessary to reproduce your analysis. If your dataset is too large to share easily, let us know in advance so that we can find a workaround. If you have a reason to prefer a presentation format other than a notebook, likewise let us know so that we can discuss the options.\n",
    "\n",
    "Your report should have four basic sections (provided in cells below for ease of reference):\n",
    "\n",
    "1. **Introduction and hypothesis.** What problem are you working on? Why is it interesting and important? What have other people said about it? What do you expect to find?\n",
    "2. **Corpus, data, and methods.** What data have you used? Where did it come from? How did you collect it? What are its limitations or omissions? What major methods will you use to analyze it? Why are those methods the appropriate ones?\n",
    "3. **Results.** What did you find? How did you find it? How should we read your figures?\n",
    "4. **Discussion and conclusions.** What does it all mean? Do your results support your hypothesis? Why or why not? What are the limitations of your study and how might those limitations be addressed in future work?\n",
    "\n",
    "Within each of those sections, you may use as many code and markdown cells as you like. You may, of course, address additional questions or issues not listed above.\n",
    "\n",
    "All code used in the project should be present in the notebook (except for widely-available libraries that you import), but **be sure that we can read and understand your report in full without rerunning the code**. Be sure, too, to explain what you're doing along the way, both by describing your data and methods and by writing clean, well commented code.\n",
    "\n",
    "### Grading\n",
    "\n",
    "This project takes the place of the take-home final exam for the course. It is worth 20% of your overall grade. You will be graded on the quality and ambition of each aspect of the project. No single component is more important than the others.\n",
    "\n",
    "### Practical details\n",
    "\n",
    "* The project is due at **11:59pm EST on Thursday, May 19, 2022** via upload to CMS of a single zip file containing your fully executed Jupyter notebook and all associated data.\n",
    "* You may work alone or in a group of up to three total members.\n",
    "    * If you work in a group, be sure to list the names of the group members.\n",
    "    * For groups, create your group on CMS and submit one notebook for the entire group. **Each group member should also submit an individual statement of responsibility** that describes in general terms who performed which parts of the project.\n",
    "* You may post questions on Ed, but should do so privately (visible to course staff only).\n",
    "* Interactive visualizations do not always work when embedded in shared notebooks. If you plan to use interactives, you may need to host them elsewhere and link to them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from   sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from   sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from   sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from   sklearn.model_selection import cross_val_score\n",
    "from   sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_data(date=''):\n",
    "    '''\n",
    "    The Billboard Hot 100 chart represents the Hot 100 songs for that week.\n",
    "    \n",
    "    date: a string, in the form \"YYYY-MM-DD\". For example, \"2022-05-16\" represents May 16, 2022. If no date specified, function\n",
    "          will select the present chart\n",
    "    returns: a pandas dataframe containing metadata for Billboard Hot 100 songs of the week of the specified date.\n",
    "    columns: rank: rank of the week (1-100)\n",
    "             date: a pandas datetime object. date of the chart as stated on the Billboard website, \n",
    "             which uses the Saturday to identify the week (so it is the same week as the user input, but the Saturday\n",
    "             of that week),\n",
    "             title: title of the song,\n",
    "             artist1: main artist,\n",
    "             artist2: a list of the rest of the artists. np.nan if there are none.\n",
    "             peak_pos: peak position of the song,\n",
    "             wks_chart: # of weeks the song has been on the chart\n",
    "             b_url: url to the billboard chart\n",
    "    '''\n",
    "    lsongs=[]\n",
    "    lartists=[]\n",
    "    artist1=[]\n",
    "    artist2=[]\n",
    "    lpeak_pos=[]\n",
    "    lwks_chart=[]\n",
    "    \n",
    "    URL='https://www.billboard.com/charts/hot-100/'+date\n",
    "\n",
    "    page=requests.get(URL)\n",
    "    soup=BeautifulSoup(page.content, 'lxml')\n",
    "  \n",
    "    ### get the first song, bc it's in a different div container\n",
    "    song1 = soup.find(\"h3\",id='title-of-a-story', class_=\"c-title a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet\")\n",
    "    lsongs.append(song1.text.strip())\n",
    "    \n",
    "    ### get the first artist, bc it's in a different div container\n",
    "    artistf=soup.find(\"span\", class_=\"c-label a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\")\n",
    "    lartists.append(artistf.text.strip())\n",
    "    \n",
    "    ### get the first peak position, bc it's in a different div container\n",
    "    nums=soup.find_all('span', class_=\"c-label a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet\")\n",
    "    nums1=[]\n",
    "    for x in nums:\n",
    "        nums1.append(x.text.strip())\n",
    "        \n",
    "    lpeak_pos.append(nums1[1])\n",
    "    ### get the first weeks on chart, bc it's in a different div container\n",
    "    lwks_chart.append(nums1[2])\n",
    "    \n",
    "    ### get last 99 songs\n",
    "    songs = soup.find_all(\"h3\", class_=\"c-title a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\", id=\"title-of-a-story\")\n",
    "    for song in songs:\n",
    "        lsongs.append(song.text.strip())\n",
    "    \n",
    "    ### get last 99 artists\n",
    "    artists = soup.find_all(\"span\", class_=\"c-label a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\")\n",
    "    for artist in artists:\n",
    "        lartists.append(artist.text.strip())\n",
    "        \n",
    "    ### get last 99 peak position\n",
    "    all_num=[]\n",
    "    peak_pos = soup.find_all(\"span\", class_=\"c-label a-font-primary-m lrv-u-padding-tb-050@mobile-max\")\n",
    "    for num in peak_pos:\n",
    "        all_num.append(num.text.strip())\n",
    "    \n",
    "    x=1\n",
    "    for peak in all_num:\n",
    "        if x <= len(all_num)-5:\n",
    "            lpeak_pos.append(all_num[x])\n",
    "            x=x+6\n",
    "\n",
    "    ### get last 99 weeks on chart\n",
    "    y=2\n",
    "    for wk in all_num:\n",
    "        if y <= len(all_num)-4:\n",
    "            lwks_chart.append(all_num[y])\n",
    "            y=y+6            \n",
    "    \n",
    "    ### get date as listed on the chart, aka the Saturday of the week of the user input\n",
    "    date=soup.find('h2', id=\"section-heading\")\n",
    "    cdate=pd.to_datetime(date.text.strip().replace(\"Week of \",''))\n",
    "    \n",
    "    \n",
    "    ### separate artists into artist1 and artist2\n",
    "    for a in lartists:\n",
    "        if (\"X &\" not in a) and (\"X Featuring\" not in a) and (\"X /\" not in a):\n",
    "            a=a.replace(\" X \",\",\")\n",
    "        a=a.replace(\"Featuring\",\",\")\n",
    "        a=a.replace(\"&\",\",\")   \n",
    "        a=a.replace(\" / \",\",\")\n",
    "        List=a.split(\",\")\n",
    "        artists = [i.strip() for i in List]\n",
    "        artist1.append(artists[0])\n",
    "        if len(artists)==1:\n",
    "            artist2.append(np.nan)\n",
    "        else:\n",
    "            artist2.append(artists[1:])\n",
    "    \n",
    "    metadata=pd.DataFrame()\n",
    "    metadata['rank']=(range(1,101)) ### get rank position\n",
    "    metadata['date']=cdate\n",
    "    metadata['title']=lsongs\n",
    "    metadata['artist1']=artist1\n",
    "    metadata['artist2']=artist2\n",
    "    metadata['peak_pos']=lpeak_pos\n",
    "    metadata['wks_chart']=lwks_chart\n",
    "    metadata['b_url']=URL\n",
    "    \n",
    "    metadata=append_lyrics(metadata)\n",
    "    metadata.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_lyrics(metadata):\n",
    "    '''\n",
    "    a helper function for song_data(). gets the song lyrics for a given song. appends the\n",
    "    song lyrics for a song from Genius.com to a \"lyrics\" column.\n",
    "    \n",
    "    If the function cannot find the song on the Genius lyrics website, it will drop the entire observation from the dataset.\n",
    "    \n",
    "    metadata: a pandas dataframe, created from song_data(). at the least contains\n",
    "              the title column and the artist1 column.\n",
    "    returns: a pandas dataframe of the original dataframe with a lyrics column and URL to the\n",
    "             Genius website the lyrics were taken from.\n",
    "    '''\n",
    "    all_lyrics=[]\n",
    "    all_URL=[]\n",
    "    title=metadata.title.values\n",
    "    artist1=metadata.artist1.values\n",
    "    for x in range(len(title)):\n",
    "        t=title[x]\n",
    "        a=artist1[x]\n",
    "  \n",
    "        t=re.sub(r'[^\\w\\s]', '', t)\n",
    "        a=re.sub(r'[!$/]', '-', a)\n",
    "        a=re.sub(r'[\"\\\\#%&;\\()*\\[\\]+,.:;<=>?@^_`{|}~]', '', a) #[\\\\]\n",
    "        URL= \"https://www.genius.com/\"+a.replace(' ','-')+'-'+t.replace(' ','-')+'-lyrics'\n",
    "        URL=URL.replace('--','-')\n",
    "        \n",
    "        page=requests.get(URL)\n",
    "        soup=BeautifulSoup(page.content, 'lxml')\n",
    "        if 'Oops! Page not found' not in soup.text.strip():\n",
    "            lyrics=soup.find_all('div', class_='Lyrics__Container-sc-1ynbvzw-6 jYfhrf')\n",
    "            Lyrics = [re.sub(r\"\\[.*?\\]\",'',i.text.strip()) for i in lyrics]\n",
    "            LYRICS=\" \".join(Lyrics)\n",
    "            all_lyrics.append(LYRICS)\n",
    "            all_URL.append(URL)\n",
    "        \n",
    "        else: \n",
    "            #print(URL)\n",
    "            metadata.drop([x], inplace=True)\n",
    "    \n",
    "    metadata['lyrics']=all_lyrics\n",
    "    metadata['g_url']=all_URL\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rank</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>artist1</th>\n",
       "      <th>artist2</th>\n",
       "      <th>peak_pos</th>\n",
       "      <th>wks_chart</th>\n",
       "      <th>b_url</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>g_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>First Class</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/</td>\n",
       "      <td>MmI been a (G), throw up the (L), sex in the (...</td>\n",
       "      <td>https://www.genius.com/Jack-Harlow-First-Class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/</td>\n",
       "      <td>Come on, Harry, we wanna say goodnight to youH...</td>\n",
       "      <td>https://www.genius.com/Harry-Styles-As-It-Was-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>Wait For U</td>\n",
       "      <td>Future</td>\n",
       "      <td>[Drake, Tems]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/</td>\n",
       "      <td>I will wait for you, for youEarly in the morni...</td>\n",
       "      <td>https://www.genius.com/Future-Wait-For-U-lyrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>Moscow Mule</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/</td>\n",
       "      <td>Si yo no te escribo, tú no me escribe', eySi t...</td>\n",
       "      <td>https://www.genius.com/Bad-Bunny-Moscow-Mule-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>Titi Me Pregunto</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/</td>\n",
       "      <td>EyTití me preguntó si tengo mucha' novia', muc...</td>\n",
       "      <td>https://www.genius.com/Bad-Bunny-Titi-Me-Pregu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>Frozen</td>\n",
       "      <td>Lil Baby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/</td>\n",
       "      <td>Can someone come unthaw my heart? I think it's...</td>\n",
       "      <td>https://www.genius.com/Lil-Baby-Frozen-lyrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>Young Harleezy</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/</td>\n",
       "      <td>Young Harleezy, y'all grew up shooting RPG'sI ...</td>\n",
       "      <td>https://www.genius.com/Jack-Harlow-Young-Harle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Sam Hunt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/</td>\n",
       "      <td>La-la-la-la-laYou can marry an architectBuild ...</td>\n",
       "      <td>https://www.genius.com/Sam-Hunt-23-lyrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>Poison</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>[Lil Wayne]</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/</td>\n",
       "      <td>Can you decide?Can you decide?OhNew musicListe...</td>\n",
       "      <td>https://www.genius.com/Jack-Harlow-Poison-lyrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>Honest</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>[Don Toliver]</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/</td>\n",
       "      <td>Honest (Honest)You're modest, I like it (I lik...</td>\n",
       "      <td>https://www.genius.com/Justin-Bieber-Honest-ly...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  rank       date             title        artist1        artist2  \\\n",
       "0       0     1 2022-05-21       First Class    Jack Harlow            NaN   \n",
       "1       1     2 2022-05-21         As It Was   Harry Styles            NaN   \n",
       "2       2     3 2022-05-21        Wait For U         Future  [Drake, Tems]   \n",
       "3       3     4 2022-05-21       Moscow Mule      Bad Bunny            NaN   \n",
       "4       4     5 2022-05-21  Titi Me Pregunto      Bad Bunny            NaN   \n",
       "..    ...   ...        ...               ...            ...            ...   \n",
       "89     95    96 2022-05-21            Frozen       Lil Baby            NaN   \n",
       "90     96    97 2022-05-21    Young Harleezy    Jack Harlow            NaN   \n",
       "91     97    98 2022-05-21                23       Sam Hunt            NaN   \n",
       "92     98    99 2022-05-21            Poison    Jack Harlow    [Lil Wayne]   \n",
       "93     99   100 2022-05-21            Honest  Justin Bieber  [Don Toliver]   \n",
       "\n",
       "   peak_pos wks_chart                                      b_url  \\\n",
       "0         1         5  https://www.billboard.com/charts/hot-100/   \n",
       "1         1         6  https://www.billboard.com/charts/hot-100/   \n",
       "2         1         2  https://www.billboard.com/charts/hot-100/   \n",
       "3         4         1  https://www.billboard.com/charts/hot-100/   \n",
       "4         5         1  https://www.billboard.com/charts/hot-100/   \n",
       "..      ...       ...                                        ...   \n",
       "89       54         2  https://www.billboard.com/charts/hot-100/   \n",
       "90       97         1  https://www.billboard.com/charts/hot-100/   \n",
       "91       50        20  https://www.billboard.com/charts/hot-100/   \n",
       "92       99         1  https://www.billboard.com/charts/hot-100/   \n",
       "93       44         2  https://www.billboard.com/charts/hot-100/   \n",
       "\n",
       "                                               lyrics  \\\n",
       "0   MmI been a (G), throw up the (L), sex in the (...   \n",
       "1   Come on, Harry, we wanna say goodnight to youH...   \n",
       "2   I will wait for you, for youEarly in the morni...   \n",
       "3   Si yo no te escribo, tú no me escribe', eySi t...   \n",
       "4   EyTití me preguntó si tengo mucha' novia', muc...   \n",
       "..                                                ...   \n",
       "89  Can someone come unthaw my heart? I think it's...   \n",
       "90  Young Harleezy, y'all grew up shooting RPG'sI ...   \n",
       "91  La-la-la-la-laYou can marry an architectBuild ...   \n",
       "92  Can you decide?Can you decide?OhNew musicListe...   \n",
       "93  Honest (Honest)You're modest, I like it (I lik...   \n",
       "\n",
       "                                                g_url  \n",
       "0   https://www.genius.com/Jack-Harlow-First-Class...  \n",
       "1   https://www.genius.com/Harry-Styles-As-It-Was-...  \n",
       "2     https://www.genius.com/Future-Wait-For-U-lyrics  \n",
       "3   https://www.genius.com/Bad-Bunny-Moscow-Mule-l...  \n",
       "4   https://www.genius.com/Bad-Bunny-Titi-Me-Pregu...  \n",
       "..                                                ...  \n",
       "89      https://www.genius.com/Lil-Baby-Frozen-lyrics  \n",
       "90  https://www.genius.com/Jack-Harlow-Young-Harle...  \n",
       "91          https://www.genius.com/Sam-Hunt-23-lyrics  \n",
       "92   https://www.genius.com/Jack-Harlow-Poison-lyrics  \n",
       "93  https://www.genius.com/Justin-Bieber-Honest-ly...  \n",
       "\n",
       "[94 rows x 11 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=song_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148\n",
      "DatetimeIndex(['2000-01-01', '2000-01-08', '2000-01-15', '2000-01-22',\n",
      "               '2000-01-29', '2000-02-05', '2000-02-12', '2000-02-19',\n",
      "               '2000-02-26', '2000-03-04',\n",
      "               ...\n",
      "               '2021-10-23', '2021-10-30', '2021-11-06', '2021-11-13',\n",
      "               '2021-11-20', '2021-11-27', '2021-12-04', '2021-12-11',\n",
      "               '2021-12-18', '2021-12-25'],\n",
      "              dtype='datetime64[ns]', length=1148, freq='W-SAT')\n"
     ]
    }
   ],
   "source": [
    "dates=pd.date_range(start='2000-01-01',end='2021-12-31',freq='W-SAT')\n",
    "print(len(dates))\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dates=[date.strftime('%Y-%m-%d') for date in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testdate=[Dates[0],Dates[1]]\n",
    "#testsongs=[]\n",
    "#for date in testdate:\n",
    "#    testsongs.append(song_data(date))\n",
    "#testdf=pd.concat(testsongs)\n",
    "#testdf.reset_index(drop=True,inplace=True)\n",
    "#testdf.to_csv('testdf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gaby run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates2000_2010=Dates[:len(Dates)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2000_2010=[]\n",
    "for date in dates2000_2010:\n",
    "    songs2000_2010.append(song_data(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.concat(songs_2000_2010)\n",
    "df1.reset_index(inplace=True)\n",
    "df1.to_csv('df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estelle run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates2011_2020=Dates[len(Dates)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2011_2020=[]\n",
    "for date in dates2011_2020:\n",
    "    songs2011_2020.append(song_data(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.concat(songs_2011_2020)\n",
    "df2.reset_index(inplace=True)\n",
    "df2.to_csv('df2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Discussion and conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resources consulted\n",
    "https://stackoverflow.com/questions/640001/how-can-i-remove-text-within-parentheses-with-a-regex\n",
    "https://www.pythontutorial.net/python-regex/python-regex-sub/\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
