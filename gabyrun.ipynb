{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project guidelines\n",
    "\n",
    "**Note:** Use these guidelines if and only if you are pursuing a **final project of your own design**. For those taking the final exam instead of the project, see the (separate) [final exam notebook](https://github.com/wilkens-teaching/info3350-s22/blob/main/final_exam/exam.ipynb).\n",
    "\n",
    "## Guidelines\n",
    "\n",
    "These guidelines are intended for **undergraduates enrolled in INFO 3350**. If you are a graduate student enrolled in INFO 6350, you're welcome to consult the information below, but you have wider latitude to design and develop your project in line with your research goals.\n",
    "\n",
    "### The task\n",
    "\n",
    "Your task is to: identify an interesting problem connected to the humanities or humanistic social sciences that's addressable with the help of computational methods, formulate a hypothesis about it, devise an experiment or experiments to test your hypothesis, present the results of your investigations, and discuss your findings.\n",
    "\n",
    "These tasks essentially replicate the process of writing an academic paper. You can think of your project as a paper in miniature.\n",
    "\n",
    "You are free to present each of these tasks as you see fit. You should use narrative text (that is, your own writing in a markdown cell), citations of others' work, numerical results, tables of data, and static and/or interactive visualizations as appropriate. Total length is flexible and depends on the number of people involved in the work, as well as the specific balance you strike between the ambition of your question and the sophistication of your methods. But be aware that numbers never, ever speak for themselves. Quantitative results presented without substantial discussion will not earn high marks. \n",
    "\n",
    "Your project should reflect, at minimum, ten or more hours of work by each participant, though you will be graded on the quality of your work, not the amount of time it took you to produce it.\n",
    "\n",
    "#### Pick an important and interesting problem!\n",
    "\n",
    "No amount of technical sophistication will overcome a fundamentally uninteresting problem at the core of your work. You have seen many pieces of successful computational humanities research over the course of the semester. You might use these as a guide to the kinds of problems that interest scholars in a range of humanities disciplines. You may also want to spend some time in the library, reading recent books and articles in the professional literature. **Problem selection and motivation are integral parts of the project.** Do not neglect them.\n",
    "\n",
    "### Format\n",
    "\n",
    "You should submit your project as a Jupyter notebook, along with all data necessary to reproduce your analysis. If your dataset is too large to share easily, let us know in advance so that we can find a workaround. If you have a reason to prefer a presentation format other than a notebook, likewise let us know so that we can discuss the options.\n",
    "\n",
    "Your report should have four basic sections (provided in cells below for ease of reference):\n",
    "\n",
    "1. **Introduction and hypothesis.** What problem are you working on? Why is it interesting and important? What have other people said about it? What do you expect to find?\n",
    "2. **Corpus, data, and methods.** What data have you used? Where did it come from? How did you collect it? What are its limitations or omissions? What major methods will you use to analyze it? Why are those methods the appropriate ones?\n",
    "3. **Results.** What did you find? How did you find it? How should we read your figures?\n",
    "4. **Discussion and conclusions.** What does it all mean? Do your results support your hypothesis? Why or why not? What are the limitations of your study and how might those limitations be addressed in future work?\n",
    "\n",
    "Within each of those sections, you may use as many code and markdown cells as you like. You may, of course, address additional questions or issues not listed above.\n",
    "\n",
    "All code used in the project should be present in the notebook (except for widely-available libraries that you import), but **be sure that we can read and understand your report in full without rerunning the code**. Be sure, too, to explain what you're doing along the way, both by describing your data and methods and by writing clean, well commented code.\n",
    "\n",
    "### Grading\n",
    "\n",
    "This project takes the place of the take-home final exam for the course. It is worth 20% of your overall grade. You will be graded on the quality and ambition of each aspect of the project. No single component is more important than the others.\n",
    "\n",
    "### Practical details\n",
    "\n",
    "* The project is due at **11:59pm EST on Thursday, May 19, 2022** via upload to CMS of a single zip file containing your fully executed Jupyter notebook and all associated data.\n",
    "* You may work alone or in a group of up to three total members.\n",
    "    * If you work in a group, be sure to list the names of the group members.\n",
    "    * For groups, create your group on CMS and submit one notebook for the entire group. **Each group member should also submit an individual statement of responsibility** that describes in general terms who performed which parts of the project.\n",
    "* You may post questions on Ed, but should do so privately (visible to course staff only).\n",
    "* Interactive visualizations do not always work when embedded in shared notebooks. If you plan to use interactives, you may need to host them elsewhere and link to them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from   sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from   sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from   sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from   sklearn.model_selection import cross_val_score\n",
    "from   sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_data(date=''):\n",
    "    '''\n",
    "    The Billboard Hot 100 chart represents the Hot 100 songs for that week.\n",
    "    \n",
    "    date: a string, in the form \"YYYY-MM-DD\". For example, \"2022-05-16\" represents May 16, 2022. If no date specified, function\n",
    "          will select the present chart\n",
    "    returns: a pandas dataframe containing metadata for Billboard Hot 100 songs of the week of the specified date.\n",
    "    columns: rank: rank of the week (1-100)\n",
    "             date: a pandas datetime object. date of the chart as stated on the Billboard website, \n",
    "             which uses the Saturday to identify the week (so it is the same week as the user input, but the Saturday\n",
    "             of that week),\n",
    "             title: title of the song,\n",
    "             artist1: main artist,\n",
    "             artist2: a list of the rest of the artists. np.nan if there are none.\n",
    "             peak_pos: peak position of the song,\n",
    "             wks_chart: # of weeks the song has been on the chart\n",
    "             b_url: url to the billboard chart\n",
    "    '''\n",
    "    lsongs=[]\n",
    "    lartists=[]\n",
    "    artist1=[]\n",
    "    artist2=[]\n",
    "    lpeak_pos=[]\n",
    "    lwks_chart=[]\n",
    "    \n",
    "    URL='https://www.billboard.com/charts/hot-100/'+date\n",
    "\n",
    "    page=requests.get(URL)\n",
    "    soup=BeautifulSoup(page.content, 'lxml')\n",
    "  \n",
    "    ### get the first song, bc it's in a different div container\n",
    "    song1 = soup.find(\"h3\",id='title-of-a-story', class_=\"c-title a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet\")\n",
    "    lsongs.append(song1.text.strip())\n",
    "    \n",
    "    ### get the first artist, bc it's in a different div container\n",
    "    artistf=soup.find(\"span\", class_=\"c-label a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\")\n",
    "    lartists.append(artistf.text.strip())\n",
    "    \n",
    "    ### get the first peak position, bc it's in a different div container\n",
    "    nums=soup.find_all('span', class_=\"c-label a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet\")\n",
    "    nums1=[]\n",
    "    for x in nums:\n",
    "        nums1.append(x.text.strip())\n",
    "        \n",
    "    lpeak_pos.append(nums1[1])\n",
    "    ### get the first weeks on chart, bc it's in a different div container\n",
    "    lwks_chart.append(nums1[2])\n",
    "    \n",
    "    ### get last 99 songs\n",
    "    songs = soup.find_all(\"h3\", class_=\"c-title a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\", id=\"title-of-a-story\")\n",
    "    for song in songs:\n",
    "        lsongs.append(song.text.strip())\n",
    "    \n",
    "    ### get last 99 artists\n",
    "    artists = soup.find_all(\"span\", class_=\"c-label a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\")\n",
    "    for artist in artists:\n",
    "        lartists.append(artist.text.strip())\n",
    "        \n",
    "    ### get last 99 peak position\n",
    "    all_num=[]\n",
    "    peak_pos = soup.find_all(\"span\", class_=\"c-label a-font-primary-m lrv-u-padding-tb-050@mobile-max\")\n",
    "    for num in peak_pos:\n",
    "        all_num.append(num.text.strip())\n",
    "    \n",
    "    x=1\n",
    "    for peak in all_num:\n",
    "        if x <= len(all_num)-5:\n",
    "            lpeak_pos.append(all_num[x])\n",
    "            x=x+6\n",
    "\n",
    "    ### get last 99 weeks on chart\n",
    "    y=2\n",
    "    for wk in all_num:\n",
    "        if y <= len(all_num)-4:\n",
    "            lwks_chart.append(all_num[y])\n",
    "            y=y+6            \n",
    "    \n",
    "    ### get date as listed on the chart, aka the Saturday of the week of the user input\n",
    "    date=soup.find('h2', id=\"section-heading\")\n",
    "    cdate=pd.to_datetime(date.text.strip().replace(\"Week of \",''))\n",
    "    \n",
    "    \n",
    "    ### separate artists into artist1 and artist2\n",
    "    for a in lartists:\n",
    "        if (\"X &\" not in a) and (\"X Featuring\" not in a) and (\"X /\" not in a):\n",
    "            a=a.replace(\" X \",\",\")\n",
    "        a=a.replace(\"Featuring\",\",\")\n",
    "        a=a.replace(\"&\",\",\")   \n",
    "        a=a.replace(\" / \",\",\")\n",
    "        List=a.split(\",\")\n",
    "        artists = [i.strip() for i in List]\n",
    "        artist1.append(artists[0])\n",
    "        if len(artists)==1:\n",
    "            artist2.append(np.nan)\n",
    "        else:\n",
    "            artist2.append(artists[1:])\n",
    "    \n",
    "    metadata=pd.DataFrame()\n",
    "    metadata['rank']=(range(1,101)) ### get rank position\n",
    "    metadata['date']=cdate\n",
    "    metadata['title']=lsongs\n",
    "    metadata['artist1']=artist1\n",
    "    metadata['artist2']=artist2\n",
    "    metadata['peak_pos']=lpeak_pos\n",
    "    metadata['wks_chart']=lwks_chart\n",
    "    metadata['b_url']=URL\n",
    "    \n",
    "    metadata=append_lyrics(metadata)\n",
    "    metadata.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_lyrics(metadata):\n",
    "    '''\n",
    "    a helper function for song_data(). gets the song lyrics for a given song. appends the\n",
    "    song lyrics for a song from Genius.com to a \"lyrics\" column.\n",
    "    \n",
    "    If the function cannot find the song on the Genius lyrics website, it will drop the entire observation from the dataset.\n",
    "    \n",
    "    metadata: a pandas dataframe, created from song_data(). at the least contains\n",
    "              the title column and the artist1 column.\n",
    "    returns: a pandas dataframe of the original dataframe with a lyrics column and URL to the\n",
    "             Genius website the lyrics were taken from.\n",
    "    '''\n",
    "    all_lyrics=[]\n",
    "    all_URL=[]\n",
    "    title=metadata.title.values\n",
    "    artist1=metadata.artist1.values\n",
    "    for x in range(len(title)):\n",
    "        t=title[x]\n",
    "        a=artist1[x]\n",
    "  \n",
    "        t=re.sub(r'[^\\w\\s]', '', t)\n",
    "        a=re.sub(r'[!$/]', '-', a)\n",
    "        a=re.sub(r'[\"\\\\#%&;\\()*\\[\\]+,.:;<=>?@^_`{|}~]', '', a) #[\\\\]\n",
    "        URL= \"https://www.genius.com/\"+a.replace(' ','-')+'-'+t.replace(' ','-')+'-lyrics'\n",
    "        URL=URL.replace('--','-')\n",
    "        \n",
    "        page=requests.get(URL)\n",
    "        soup=BeautifulSoup(page.content, 'lxml')\n",
    "        if 'Oops! Page not found' not in soup.text.strip():\n",
    "            lyrics=soup.find_all('div', class_='Lyrics__Container-sc-1ynbvzw-6 jYfhrf')\n",
    "            Lyrics = [re.sub(r\"\\[.*?\\]\",'',i.text.strip()) for i in lyrics]\n",
    "            LYRICS=\" \".join(Lyrics)\n",
    "            all_lyrics.append(LYRICS)\n",
    "            all_URL.append(URL)\n",
    "        \n",
    "        else: \n",
    "            #print(URL)\n",
    "            metadata.drop([x], inplace=True)\n",
    "    \n",
    "    metadata['lyrics']=all_lyrics\n",
    "    metadata['g_url']=all_URL\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "DatetimeIndex(['2000-07-15', '2000-07-22', '2000-07-29', '2000-08-05',\n",
      "               '2000-08-12', '2000-08-19', '2000-08-26', '2000-09-02',\n",
      "               '2000-09-09', '2000-09-16', '2000-09-23', '2000-09-30',\n",
      "               '2000-10-07', '2000-10-14', '2000-10-21', '2000-10-28',\n",
      "               '2000-11-04', '2000-11-11', '2000-11-18', '2000-11-25',\n",
      "               '2000-12-02', '2000-12-09', '2000-12-16', '2000-12-23',\n",
      "               '2000-12-30'],\n",
      "              dtype='datetime64[ns]', freq='W-SAT')\n"
     ]
    }
   ],
   "source": [
    "dates=pd.date_range(start='2000-07-15',end='2000-12-31',freq='W-SAT')\n",
    "print(len(dates))\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dates=[date.strftime('%Y-%m-%d') for date in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-07-15\n",
      "2000-07-22\n",
      "2000-07-29\n",
      "2000-08-05\n",
      "2000-08-12\n",
      "2000-08-19\n",
      "2000-08-26\n",
      "2000-09-02\n",
      "2000-09-09\n",
      "2000-09-16\n",
      "2000-09-23\n",
      "2000-09-30\n",
      "2000-10-07\n",
      "2000-10-14\n",
      "2000-10-21\n",
      "2000-10-28\n",
      "2000-11-04\n",
      "2000-11-11\n",
      "2000-11-18\n",
      "2000-11-25\n",
      "2000-12-02\n",
      "2000-12-09\n",
      "2000-12-16\n",
      "2000-12-23\n",
      "2000-12-30\n"
     ]
    }
   ],
   "source": [
    "songs=[]\n",
    "for date in Dates:\n",
    "    songs.append(song_data(date))\n",
    "    print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat(songs)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv('df2000_0101_to_2000_0708.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2000=pd.concat([df,df2])\n",
    "songs2000.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2000.to_csv('songs2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>artist1</th>\n",
       "      <th>artist2</th>\n",
       "      <th>peak_pos</th>\n",
       "      <th>wks_chart</th>\n",
       "      <th>b_url</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>g_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-07-15 00:00:00</td>\n",
       "      <td>Everything You Want</td>\n",
       "      <td>Vertical Horizon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2000-...</td>\n",
       "      <td>Somewhere there's speakingIt's already coming ...</td>\n",
       "      <td>https://www.genius.com/Vertical-Horizon-Everyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2000-07-15 00:00:00</td>\n",
       "      <td>Try Again</td>\n",
       "      <td>Aaliyah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2000-...</td>\n",
       "      <td>It's been a long time (Long time)We shouldn't ...</td>\n",
       "      <td>https://www.genius.com/Aaliyah-Try-Again-lyrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2000-07-15 00:00:00</td>\n",
       "      <td>Be With You</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2000-...</td>\n",
       "      <td>Monday night and I feel so lowI count the hour...</td>\n",
       "      <td>https://www.genius.com/Enrique-Iglesias-Be-Wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2000-07-15 00:00:00</td>\n",
       "      <td>I Wanna Know</td>\n",
       "      <td>Joe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2000-...</td>\n",
       "      <td>YeahOh-oh, yeahAlright, oh, oh, ohIt's amazing...</td>\n",
       "      <td>https://www.genius.com/Joe-I-Wanna-Know-lyrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2000-07-15 00:00:00</td>\n",
       "      <td>Bent</td>\n",
       "      <td>matchbox twenty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2000-...</td>\n",
       "      <td>And if I fall along the wayPick me up and dust...</td>\n",
       "      <td>https://www.genius.com/matchbox-twenty-Bent-ly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4821</th>\n",
       "      <td>95</td>\n",
       "      <td>2000-07-08</td>\n",
       "      <td>What You Want</td>\n",
       "      <td>DMX</td>\n",
       "      <td>['Sisqo']</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2000-...</td>\n",
       "      <td>Y'all niggas is dead, dead!What the fuck is wr...</td>\n",
       "      <td>https://www.genius.com/DMX-What-You-Want-lyrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4822</th>\n",
       "      <td>96</td>\n",
       "      <td>2000-07-08</td>\n",
       "      <td>You Owe Me</td>\n",
       "      <td>NAS</td>\n",
       "      <td>['Ginuwine']</td>\n",
       "      <td>59</td>\n",
       "      <td>16</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2000-...</td>\n",
       "      <td>Uh, it's real, it's real, it's realUh, uh, owe...</td>\n",
       "      <td>https://www.genius.com/NAS-You-Owe-Me-lyrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4823</th>\n",
       "      <td>97</td>\n",
       "      <td>2000-07-08</td>\n",
       "      <td>Dancing Queen</td>\n",
       "      <td>A*Teens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2000-...</td>\n",
       "      <td>Ooh, you can danceYou can jiveHaving the time ...</td>\n",
       "      <td>https://www.genius.com/ATeens-Dancing-Queen-ly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4824</th>\n",
       "      <td>98</td>\n",
       "      <td>2000-07-08</td>\n",
       "      <td>Don't Call Me Baby</td>\n",
       "      <td>Madison Avenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2000-...</td>\n",
       "      <td>You and me, we have an opportunityAnd we could...</td>\n",
       "      <td>https://www.genius.com/Madison-Avenue-Dont-Cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4825</th>\n",
       "      <td>100</td>\n",
       "      <td>2000-07-08</td>\n",
       "      <td>Riddle</td>\n",
       "      <td>En Vogue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.billboard.com/charts/hot-100/2000-...</td>\n",
       "      <td>One little riddleTwo little, three littleFour ...</td>\n",
       "      <td>https://www.genius.com/En-Vogue-Riddle-lyrics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4826 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rank                 date                title           artist1  \\\n",
       "0        1  2000-07-15 00:00:00  Everything You Want  Vertical Horizon   \n",
       "1        2  2000-07-15 00:00:00            Try Again           Aaliyah   \n",
       "2        3  2000-07-15 00:00:00          Be With You  Enrique Iglesias   \n",
       "3        4  2000-07-15 00:00:00         I Wanna Know               Joe   \n",
       "4        6  2000-07-15 00:00:00                 Bent   matchbox twenty   \n",
       "...    ...                  ...                  ...               ...   \n",
       "4821    95           2000-07-08        What You Want               DMX   \n",
       "4822    96           2000-07-08           You Owe Me               NAS   \n",
       "4823    97           2000-07-08        Dancing Queen           A*Teens   \n",
       "4824    98           2000-07-08   Don't Call Me Baby    Madison Avenue   \n",
       "4825   100           2000-07-08               Riddle          En Vogue   \n",
       "\n",
       "           artist2 peak_pos wks_chart  \\\n",
       "0              NaN        1        26   \n",
       "1              NaN        1        18   \n",
       "2              NaN        1        16   \n",
       "3              NaN        4        29   \n",
       "4              NaN        6        12   \n",
       "...            ...      ...       ...   \n",
       "4821     ['Sisqo']       95         2   \n",
       "4822  ['Ginuwine']       59        16   \n",
       "4823           NaN       97         1   \n",
       "4824           NaN       98         1   \n",
       "4825           NaN       92         4   \n",
       "\n",
       "                                                  b_url  \\\n",
       "0     https://www.billboard.com/charts/hot-100/2000-...   \n",
       "1     https://www.billboard.com/charts/hot-100/2000-...   \n",
       "2     https://www.billboard.com/charts/hot-100/2000-...   \n",
       "3     https://www.billboard.com/charts/hot-100/2000-...   \n",
       "4     https://www.billboard.com/charts/hot-100/2000-...   \n",
       "...                                                 ...   \n",
       "4821  https://www.billboard.com/charts/hot-100/2000-...   \n",
       "4822  https://www.billboard.com/charts/hot-100/2000-...   \n",
       "4823  https://www.billboard.com/charts/hot-100/2000-...   \n",
       "4824  https://www.billboard.com/charts/hot-100/2000-...   \n",
       "4825  https://www.billboard.com/charts/hot-100/2000-...   \n",
       "\n",
       "                                                 lyrics  \\\n",
       "0     Somewhere there's speakingIt's already coming ...   \n",
       "1     It's been a long time (Long time)We shouldn't ...   \n",
       "2     Monday night and I feel so lowI count the hour...   \n",
       "3     YeahOh-oh, yeahAlright, oh, oh, ohIt's amazing...   \n",
       "4     And if I fall along the wayPick me up and dust...   \n",
       "...                                                 ...   \n",
       "4821  Y'all niggas is dead, dead!What the fuck is wr...   \n",
       "4822  Uh, it's real, it's real, it's realUh, uh, owe...   \n",
       "4823  Ooh, you can danceYou can jiveHaving the time ...   \n",
       "4824  You and me, we have an opportunityAnd we could...   \n",
       "4825  One little riddleTwo little, three littleFour ...   \n",
       "\n",
       "                                                  g_url  \n",
       "0     https://www.genius.com/Vertical-Horizon-Everyt...  \n",
       "1       https://www.genius.com/Aaliyah-Try-Again-lyrics  \n",
       "2     https://www.genius.com/Enrique-Iglesias-Be-Wit...  \n",
       "3        https://www.genius.com/Joe-I-Wanna-Know-lyrics  \n",
       "4     https://www.genius.com/matchbox-twenty-Bent-ly...  \n",
       "...                                                 ...  \n",
       "4821    https://www.genius.com/DMX-What-You-Want-lyrics  \n",
       "4822       https://www.genius.com/NAS-You-Owe-Me-lyrics  \n",
       "4823  https://www.genius.com/ATeens-Dancing-Queen-ly...  \n",
       "4824  https://www.genius.com/Madison-Avenue-Dont-Cal...  \n",
       "4825      https://www.genius.com/En-Vogue-Riddle-lyrics  \n",
       "\n",
       "[4826 rows x 10 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Discussion and conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resources consulted\n",
    "https://stackoverflow.com/questions/640001/how-can-i-remove-text-within-parentheses-with-a-regex\n",
    "https://www.pythontutorial.net/python-regex/python-regex-sub/\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
